{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T13:23:49.198866Z",
     "start_time": "2021-03-01T13:23:38.972093Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Using cached gensim-3.8.3-cp37-cp37m-macosx_10_9_x86_64.whl (24.2 MB)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in /Users/ltaing/opt/anaconda3/lib/python3.7/site-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5.0 in /Users/ltaing/opt/anaconda3/lib/python3.7/site-packages (from gensim) (1.14.0)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-4.2.0.tar.gz (119 kB)\n",
      "\u001b[K     |████████████████████████████████| 119 kB 2.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.11.3 in /Users/ltaing/opt/anaconda3/lib/python3.7/site-packages (from gensim) (1.18.1)\n",
      "Building wheels for collected packages: smart-open\n",
      "  Building wheel for smart-open (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for smart-open: filename=smart_open-4.2.0-py3-none-any.whl size=109630 sha256=160f5c088d80c483d830724bd37c45611e4c08cd761e519a0e2de9a9e19ad414\n",
      "  Stored in directory: /Users/ltaing/Library/Caches/pip/wheels/25/88/e3/7cd51a6379cac37213cac47545a27688782752ff66351b953d\n",
      "Successfully built smart-open\n",
      "Installing collected packages: smart-open, gensim\n",
      "Successfully installed gensim-3.8.3 smart-open-4.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T16:01:18.564981Z",
     "start_time": "2021-03-01T16:01:18.558292Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import string\n",
    "import re\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, roc_curve\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "import joblib\n",
    "\n",
    "import gensim\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T13:24:28.499060Z",
     "start_time": "2021-03-01T13:24:28.475817Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('tfidf', TfidfVectorizer()),\n",
      "                ('clf', SVC(C=1000, gamma=0.001))])\n"
     ]
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "import joblib\n",
    "\n",
    "pipeline = joblib.load('./sentiment_pipe.joblib')\n",
    "print(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T13:27:54.254550Z",
     "start_time": "2021-03-01T13:27:53.989927Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.26      0.39       598\n",
      "           1       0.69      0.95      0.80      1019\n",
      "\n",
      "    accuracy                           0.70      1617\n",
      "   macro avg       0.72      0.61      0.59      1617\n",
      "weighted avg       0.71      0.70      0.65      1617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "import pandas as pd\n",
    " \n",
    "df = pd.read_csv(\"comments_train.csv\")\n",
    "base_model = load('sentiment_pipe.joblib')\n",
    "\n",
    "y_test = df[\"sentiment\"].apply(lambda x: 1 if x==\"Positive\" else 0).values\n",
    "y_pred = base_model.predict(df[\"comment\"].values)\n",
    " \n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T13:28:51.711690Z",
     "start_time": "2021-03-01T13:28:51.695754Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                comment sentiment\n",
      "0     J'ai réservé ma table quelques mois à l'avance...  Positive\n",
      "1     Que dire... Nicolas sale est un chef d excepti...  Positive\n",
      "2     Dans une rue tranquille non loin du Panthéon u...  Positive\n",
      "3     Rien à redire le restaurant est irréprochablem...  Positive\n",
      "4     Comme avec les autres commentaires nos repas é...  Positive\n",
      "...                                                 ...       ...\n",
      "1612  Le service a été rapide et les crêpes très bon...  Positive\n",
      "1613  Restaurant excellent bon rapport qualité-prix ...  Positive\n",
      "1614  Incroyable mais vrai 190€ la baguette ! Que di...  Negative\n",
      "1615  Un japonais assez chic des beaux quartiers. No...  Positive\n",
      "1616  Accueil très chaleureux avec un personnel jeun...  Positive\n",
      "\n",
      "[1617 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/ltaing/Documents/SIMPLON DATA IA/TITRE PRO/CP_1/API-REST-FLASK-V2/app/model/comments_train.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T13:29:04.622243Z",
     "start_time": "2021-03-01T13:29:04.272047Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='sentiment'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.sentiment.value_counts().plot(kind='pie', autopct='%1.0f%%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T13:42:30.736817Z",
     "start_time": "2021-03-01T13:42:30.735066Z"
    }
   },
   "source": [
    "## Data Preprocessing    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T13:32:43.719513Z",
     "start_time": "2021-03-01T13:32:43.710131Z"
    }
   },
   "source": [
    "Text Cleaning\n",
    "\n",
    "Before we start using the tweets’ text we need to clean it. We’ll do the this in the class CleanText. With this class we’ll perform the following actions:\n",
    "\n",
    "    remove the mentions.\n",
    "    remove the hash tag sign (#) but not the actual tag as this may contain information\n",
    "    set all words to lowercase\n",
    "    remove all punctuations, including the question and exclamation marks\n",
    "    remove the URLs as they do not contain useful information. We did not notice a difference in the number of URLs used between the sentiment classes\n",
    "    make sure to convert the emojis into one word.\n",
    "    remove digits\n",
    "    remove stopwords\n",
    "    apply the PorterStemmer to keep the stem of the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T13:41:14.537774Z",
     "start_time": "2021-03-01T13:41:14.527894Z"
    }
   },
   "outputs": [],
   "source": [
    "class CleanText(BaseEstimator, TransformerMixin):\n",
    "    def remove_mentions(self, input_text):\n",
    "        return re.sub(r'@\\w+', '', input_text)\n",
    "    \n",
    "    def remove_urls(self, input_text):\n",
    "        return re.sub(r'http.?://[^\\s]+[\\s]?', '', input_text)\n",
    "    \n",
    "    def emoji_oneword(self, input_text):\n",
    "        # By compressing the underscore, the emoji is kept as one word\n",
    "        return input_text.replace('_','')\n",
    "    \n",
    "    def remove_punctuation(self, input_text):\n",
    "        # Make translation table\n",
    "        punct = string.punctuation\n",
    "        trantab = str.maketrans(punct, len(punct)*' ')  # Every punctuation symbol will be replaced by a space\n",
    "        return input_text.translate(trantab)    \n",
    "    \n",
    "    def remove_digits(self, input_text):\n",
    "        return re.sub('\\d+', '', input_text)\n",
    "    \n",
    "    def to_lower(self, input_text):\n",
    "        return input_text.lower()\n",
    "    \n",
    "    def remove_stopwords(self, input_text):\n",
    "        stopwords_list = stopwords.words('french')\n",
    "        # Some words which might indicate a certain sentiment are kept via a whitelist\n",
    "        whitelist = [\"non\", \"jamais\", \"bien\"]\n",
    "        words = input_text.split() \n",
    "        clean_words = [word for word in words if (word not in stopwords_list or word in whitelist) and len(word) > 1] \n",
    "        return \" \".join(clean_words) \n",
    "    \n",
    "    def stemming(self, input_text):\n",
    "        porter = PorterStemmer()\n",
    "        words = input_text.split() \n",
    "        stemmed_words = [porter.stem(word) for word in words]\n",
    "        return \" \".join(stemmed_words)\n",
    "    \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, **transform_params):\n",
    "        clean_X = X.apply(self.remove_mentions).apply(self.remove_urls).apply(self.emoji_oneword).apply(self.remove_punctuation).apply(self.remove_digits).apply(self.to_lower).apply(self.remove_stopwords).apply(self.stemming)\n",
    "        return clean_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T13:41:15.983365Z",
     "start_time": "2021-03-01T13:41:15.146500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1154    petit halt déjeuner aprè visit exposit grand p...\n",
       "462     accueil inadmiss vendeus aprè midi connaît ni ...\n",
       "1352    bon frai innov revanch pu profit tabl soleil s...\n",
       "1121    consommé truff blanch dont oublierai somptueus...\n",
       "988     déjeuner entr collègu bien agréabl servic atte...\n",
       "Name: comment, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct = CleanText()\n",
    "sr_clean = ct.fit_transform(df.comment)\n",
    "sr_clean.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One side-effect of text cleaning is that some rows do not have any words left in their text. For the CountVectorizer and TfIdfVectorizer this does not pose a problem. Yet, for the Word2Vec algorithm this causes an error. There are different strategies to deal with these missing values.\n",
    "\n",
    "    Remove the complete row, but in a production environment this is not desirable.\n",
    "    Impute the missing value with some placeholder text like *[no_text]*\n",
    "    When applying Word2Vec: use the average of all vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T14:25:18.734235Z",
     "start_time": "2021-03-01T14:25:18.725243Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 records have no words left after text cleaning\n"
     ]
    }
   ],
   "source": [
    "empty_clean = sr_clean == ''\n",
    "print('{} records have no words left after text cleaning'.format(sr_clean[empty_clean].count()))\n",
    "sr_clean.loc[empty_clean] = '[no_text]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T14:25:19.272615Z",
     "start_time": "2021-03-01T14:25:19.263323Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['comment', 'sentiment', 'clean_text']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df['clean_text'] = sr_clean\n",
    "#df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T14:25:21.151768Z",
     "start_time": "2021-03-01T14:25:21.148064Z"
    }
   },
   "outputs": [],
   "source": [
    "class ColumnExtractor(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, cols):\n",
    "        self.cols = cols    \n",
    "        \n",
    "    def transform(self, X, **transform_params):\n",
    "        return X[self.cols]  \n",
    "    \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning and cross-validation + Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T14:40:48.311920Z",
     "start_time": "2021-03-01T14:40:48.273366Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df['comment']\n",
    "y = df[\"sentiment\"].apply(lambda x: 1 if x==\"Positive\" else 0).values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our function grid_vectwe additionally generate the classification_report on the test data. This provides some interesting metrics per target class. This might be more appropriate here. These metrics are the precision, recall and F1 score.\n",
    "\n",
    "    Precision: Of all rows we predicted to be a certain class, how many did we correctly predict?\n",
    "    Recall: Of all rows of a certain class, how many did we correctly predict?\n",
    "    F1 score: Harmonic mean of Precision and Recall.\n",
    "\n",
    "With the elements of the confusion matrix we can calculate Precision and Recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T15:54:59.715588Z",
     "start_time": "2021-03-01T15:54:59.708293Z"
    }
   },
   "outputs": [],
   "source": [
    "def grid_vect(clf, parameters_clf, X_train, X_test, parameters_text=None, vect=None, is_w2v=False):\n",
    "    \n",
    "    features = FeatureUnion([('pipe', Pipeline([('vect', vect)]))]\n",
    "                                , n_jobs=-1)    \n",
    "    pipeline = Pipeline([\n",
    "        ('features', features)\n",
    "        , ('clf', clf)\n",
    "    ])\n",
    "    \n",
    "    # Join the parameters dictionaries together\n",
    "    parameters = dict()\n",
    "    if parameters_text:\n",
    "        parameters.update(parameters_text)\n",
    "    parameters.update(parameters_clf)    # Make sure you have scikit-learn version 0.19 or higher to use multiple scoring metrics\n",
    "    grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1, scoring = 'roc_auc', cv=5)\n",
    "    \n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parameters)    \n",
    "    t0 = time()\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()    \n",
    "    print(\"Best CV score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "        \n",
    "    print(\"Test score with best_estimator_: %0.3f\" % grid_search.best_estimator_.score(X_test, y_test))\n",
    "    print(\"\\n\")\n",
    "    print(\"Classification Report Test Data\")\n",
    "    print(classification_report(y_test, grid_search.best_estimator_.predict(X_test)))\n",
    "                        \n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter grids for GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T15:55:01.070960Z",
     "start_time": "2021-03-01T15:55:01.067308Z"
    }
   },
   "outputs": [],
   "source": [
    "# Parameter grid settings for the vectorizers (Count and TFIDF)\n",
    "parameters_vect = {\n",
    "    'features__pipe__vect__max_df': (0.25, 0.5, 0.75),\n",
    "    'features__pipe__vect__ngram_range': ((1, 1), (1, 2)),\n",
    "    'features__pipe__vect__min_df': (1,2),\n",
    "    'features__pipe__vect__max_features': (1000,1500,2000,2500)\n",
    "}\n",
    "# Parameter grid settings for MultinomialNB\n",
    "parameters_mnb = {\n",
    "    'clf__alpha': (0.25, 0.5, 0.75)\n",
    "}\n",
    "# Parameter grid settings for LogisticRegression\n",
    "parameters_logreg = {\n",
    "    'clf__C': (0.25, 0.5, 1.0),\n",
    "    'clf__penalty': ('l1', 'l2')\n",
    "}\n",
    "\n",
    "# Parameter grid settings for SVC\n",
    "parameters_svc = {\n",
    "    'clf__C': [1, 10, 100,1000], \n",
    "    'clf__gamma': [1,0.1,0.01,0.001],\n",
    "    'clf__kernel': ['rbf', 'poly', 'sigmoid']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T15:55:01.707420Z",
     "start_time": "2021-03-01T15:55:01.703247Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['C', 'class_weight', 'dual', 'fit_intercept', 'intercept_scaling', 'l1_ratio', 'max_iter', 'multi_class', 'n_jobs', 'penalty', 'random_state', 'solver', 'tol', 'verbose', 'warm_start'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "print(lr.get_params().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T15:55:02.453913Z",
     "start_time": "2021-03-01T15:55:02.445665Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['C', 'break_ties', 'cache_size', 'class_weight', 'coef0', 'decision_function_shape', 'degree', 'gamma', 'kernel', 'max_iter', 'probability', 'random_state', 'shrinking', 'tol', 'verbose'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "\n",
    "print(svc.get_params().keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T15:55:03.565720Z",
     "start_time": "2021-03-01T15:55:03.563415Z"
    }
   },
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()\n",
    "logreg = LogisticRegression()\n",
    "svc = SVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T16:01:18.144780Z",
     "start_time": "2021-03-01T15:55:04.937819Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['features', 'clf']\n",
      "parameters:\n",
      "{'clf__alpha': (0.25, 0.5, 0.75),\n",
      " 'features__pipe__vect__max_df': (0.25, 0.5, 0.75),\n",
      " 'features__pipe__vect__max_features': (1000, 1500, 2000, 2500),\n",
      " 'features__pipe__vect__min_df': (1, 2),\n",
      " 'features__pipe__vect__ngram_range': ((1, 1), (1, 2))}\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "done in 12.405s\n",
      "\n",
      "Best CV score: 0.949\n",
      "Best parameters set:\n",
      "\tclf__alpha: 0.75\n",
      "\tfeatures__pipe__vect__max_df: 0.5\n",
      "\tfeatures__pipe__vect__max_features: 2500\n",
      "\tfeatures__pipe__vect__min_df: 1\n",
      "\tfeatures__pipe__vect__ngram_range: (1, 1)\n",
      "Test score with best_estimator_: 0.858\n",
      "\n",
      "\n",
      "Classification Report Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.78      0.81       122\n",
      "           1       0.87      0.91      0.89       202\n",
      "\n",
      "    accuracy                           0.86       324\n",
      "   macro avg       0.85      0.84      0.85       324\n",
      "weighted avg       0.86      0.86      0.86       324\n",
      "\n",
      "Performing grid search...\n",
      "pipeline: ['features', 'clf']\n",
      "parameters:\n",
      "{'clf__C': (0.25, 0.5, 1.0),\n",
      " 'clf__penalty': ('l1', 'l2'),\n",
      " 'features__pipe__vect__max_df': (0.25, 0.5, 0.75),\n",
      " 'features__pipe__vect__max_features': (1000, 1500, 2000, 2500),\n",
      " 'features__pipe__vect__min_df': (1, 2),\n",
      " 'features__pipe__vect__ngram_range': ((1, 1), (1, 2))}\n",
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
      "done in 19.584s\n",
      "\n",
      "Best CV score: 0.927\n",
      "Best parameters set:\n",
      "\tclf__C: 1.0\n",
      "\tclf__penalty: 'l2'\n",
      "\tfeatures__pipe__vect__max_df: 0.5\n",
      "\tfeatures__pipe__vect__max_features: 2500\n",
      "\tfeatures__pipe__vect__min_df: 1\n",
      "\tfeatures__pipe__vect__ngram_range: (1, 1)\n",
      "Test score with best_estimator_: 0.843\n",
      "\n",
      "\n",
      "Classification Report Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.72      0.78       122\n",
      "           1       0.84      0.92      0.88       202\n",
      "\n",
      "    accuracy                           0.84       324\n",
      "   macro avg       0.84      0.82      0.83       324\n",
      "weighted avg       0.84      0.84      0.84       324\n",
      "\n",
      "Performing grid search...\n",
      "pipeline: ['features', 'clf']\n",
      "parameters:\n",
      "{'clf__C': [1, 10, 100, 1000],\n",
      " 'clf__gamma': [1, 0.1, 0.01, 0.001],\n",
      " 'clf__kernel': ['rbf', 'poly', 'sigmoid'],\n",
      " 'features__pipe__vect__max_df': (0.25, 0.5, 0.75),\n",
      " 'features__pipe__vect__max_features': (1000, 1500, 2000, 2500),\n",
      " 'features__pipe__vect__min_df': (1, 2),\n",
      " 'features__pipe__vect__ngram_range': ((1, 1), (1, 2))}\n",
      "Fitting 5 folds for each of 2304 candidates, totalling 11520 fits\n",
      "done in 340.453s\n",
      "\n",
      "Best CV score: 0.925\n",
      "Best parameters set:\n",
      "\tclf__C: 10\n",
      "\tclf__gamma: 0.01\n",
      "\tclf__kernel: 'rbf'\n",
      "\tfeatures__pipe__vect__max_df: 0.5\n",
      "\tfeatures__pipe__vect__max_features: 2500\n",
      "\tfeatures__pipe__vect__min_df: 1\n",
      "\tfeatures__pipe__vect__ngram_range: (1, 1)\n",
      "Test score with best_estimator_: 0.827\n",
      "\n",
      "\n",
      "Classification Report Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.70      0.75       122\n",
      "           1       0.83      0.90      0.87       202\n",
      "\n",
      "    accuracy                           0.83       324\n",
      "   macro avg       0.82      0.80      0.81       324\n",
      "weighted avg       0.83      0.83      0.82       324\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./output/best_svc_countvect.joblib']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countvect = CountVectorizer(stop_words=stopwords.words('french')) #token_pattern=r'\\b\\w+\\b',\n",
    "\n",
    "# MultinomialNB\n",
    "best_mnb_countvect = grid_vect(mnb, parameters_mnb, X_train, X_test, parameters_text=parameters_vect, vect=countvect)\n",
    "joblib.dump(best_mnb_countvect, './output/best_mnb_countvect.joblib')\n",
    "\n",
    "# LogisticRegression\n",
    "best_logreg_countvect = grid_vect(logreg, parameters_logreg, X_train, X_test, parameters_text=parameters_vect, vect=countvect)\n",
    "joblib.dump(best_logreg_countvect, './output/best_logreg_countvect.joblib')\n",
    "\n",
    "# SVC\n",
    "best_logreg_countvect = grid_vect(svc, parameters_svc, X_train, X_test, parameters_text=parameters_vect, vect=countvect)\n",
    "joblib.dump(best_logreg_countvect, './output/best_svc_countvect.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T16:07:37.195325Z",
     "start_time": "2021-03-01T16:07:37.125452Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=5,\n",
      "             estimator=Pipeline(steps=[('features',\n",
      "                                        FeatureUnion(n_jobs=-1,\n",
      "                                                     transformer_list=[('pipe',\n",
      "                                                                        Pipeline(steps=[('vect',\n",
      "                                                                                         CountVectorizer(stop_words=['au',\n",
      "                                                                                                                     'aux',\n",
      "                                                                                                                     'avec',\n",
      "                                                                                                                     'ce',\n",
      "                                                                                                                     'ces',\n",
      "                                                                                                                     'dans',\n",
      "                                                                                                                     'de',\n",
      "                                                                                                                     'des',\n",
      "                                                                                                                     'du',\n",
      "                                                                                                                     'elle',\n",
      "                                                                                                                     'en',\n",
      "                                                                                                                     'et',\n",
      "                                                                                                                     'eux',\n",
      "                                                                                                                     'il',\n",
      "                                                                                                                     'ils',\n",
      "                                                                                                                     'je',\n",
      "                                                                                                                     'la',\n",
      "                                                                                                                     'le',\n",
      "                                                                                                                     'les',\n",
      "                                                                                                                     'leur',\n",
      "                                                                                                                     'lui',\n",
      "                                                                                                                     'ma',\n",
      "                                                                                                                     'mais',\n",
      "                                                                                                                     'me',\n",
      "                                                                                                                     'même',\n",
      "                                                                                                                     'mes',\n",
      "                                                                                                                     'moi',\n",
      "                                                                                                                     'mon',\n",
      "                                                                                                                     'ne',\n",
      "                                                                                                                     'nos', ...]))]))])),\n",
      "                                       ('clf', MultinomialNB())]),\n",
      "             n_jobs=-1,\n",
      "             param_grid={'clf__alpha': (0.25, 0.5, 0.75),\n",
      "                         'features__pipe__vect__max_df': (0.25, 0.5, 0.75),\n",
      "                         'features__pipe__vect__max_features': (1000, 1500,\n",
      "                                                                2000, 2500),\n",
      "                         'features__pipe__vect__min_df': (1, 2),\n",
      "                         'features__pipe__vect__ngram_range': ((1, 1), (1, 2))},\n",
      "             scoring='roc_auc', verbose=1)\n"
     ]
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "import joblib\n",
    "\n",
    "pipeline = joblib.load('./output/best_mnb_countvect.joblib')\n",
    "print(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T14:36:32.240760Z",
     "start_time": "2021-03-01T14:33:40.441557Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['features', 'clf']\n",
      "parameters:\n",
      "{'clf__alpha': (0.25, 0.5, 0.75),\n",
      " 'features__pipe__vect__max_df': (0.25, 0.5, 0.75),\n",
      " 'features__pipe__vect__min_df': (1, 2),\n",
      " 'features__pipe__vect__ngram_range': ((1, 1), (1, 2))}\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "done in 6.031s\n",
      "\n",
      "Best CV score: 0.890\n",
      "Best parameters set:\n",
      "\tclf__alpha: 0.25\n",
      "\tfeatures__pipe__vect__max_df: 0.75\n",
      "\tfeatures__pipe__vect__min_df: 1\n",
      "\tfeatures__pipe__vect__ngram_range: (1, 1)\n",
      "Test score with best_estimator_: 0.895\n",
      "\n",
      "\n",
      "Classification Report Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.84      0.87        68\n",
      "           1       0.89      0.94      0.91        94\n",
      "\n",
      "    accuracy                           0.90       162\n",
      "   macro avg       0.90      0.89      0.89       162\n",
      "weighted avg       0.90      0.90      0.89       162\n",
      "\n",
      "Performing grid search...\n",
      "pipeline: ['features', 'clf']\n",
      "parameters:\n",
      "{'clf__C': (0.25, 0.5, 1.0),\n",
      " 'clf__penalty': ('l1', 'l2'),\n",
      " 'features__pipe__vect__max_df': (0.25, 0.5, 0.75),\n",
      " 'features__pipe__vect__min_df': (1, 2),\n",
      " 'features__pipe__vect__ngram_range': ((1, 1), (1, 2))}\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "done in 8.367s\n",
      "\n",
      "Best CV score: 0.868\n",
      "Best parameters set:\n",
      "\tclf__C: 1.0\n",
      "\tclf__penalty: 'l2'\n",
      "\tfeatures__pipe__vect__max_df: 0.75\n",
      "\tfeatures__pipe__vect__min_df: 2\n",
      "\tfeatures__pipe__vect__ngram_range: (1, 2)\n",
      "Test score with best_estimator_: 0.870\n",
      "\n",
      "\n",
      "Classification Report Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.75      0.83        68\n",
      "           1       0.84      0.96      0.90        94\n",
      "\n",
      "    accuracy                           0.87       162\n",
      "   macro avg       0.88      0.85      0.86       162\n",
      "weighted avg       0.88      0.87      0.87       162\n",
      "\n",
      "Performing grid search...\n",
      "pipeline: ['features', 'clf']\n",
      "parameters:\n",
      "{'clf__C': [1, 10, 100, 1000],\n",
      " 'clf__gamma': [1, 0.1, 0.01, 0.001],\n",
      " 'clf__kernel': ['rbf', 'poly', 'sigmoid'],\n",
      " 'features__pipe__vect__max_df': (0.25, 0.5, 0.75),\n",
      " 'features__pipe__vect__min_df': (1, 2),\n",
      " 'features__pipe__vect__ngram_range': ((1, 1), (1, 2))}\n",
      "Fitting 5 folds for each of 576 candidates, totalling 2880 fits\n",
      "done in 156.373s\n",
      "\n",
      "Best CV score: 0.869\n",
      "Best parameters set:\n",
      "\tclf__C: 10\n",
      "\tclf__gamma: 0.01\n",
      "\tclf__kernel: 'rbf'\n",
      "\tfeatures__pipe__vect__max_df: 0.25\n",
      "\tfeatures__pipe__vect__min_df: 2\n",
      "\tfeatures__pipe__vect__ngram_range: (1, 2)\n",
      "Test score with best_estimator_: 0.877\n",
      "\n",
      "\n",
      "Classification Report Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.79      0.84        68\n",
      "           1       0.86      0.94      0.90        94\n",
      "\n",
      "    accuracy                           0.88       162\n",
      "   macro avg       0.88      0.87      0.87       162\n",
      "weighted avg       0.88      0.88      0.88       162\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./output/best_svc_countvect.pkl']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countvect = CountVectorizer()\n",
    "\n",
    "# MultinomialNB\n",
    "best_mnb_countvect = grid_vect(mnb, parameters_mnb, X_train, X_test, parameters_text=parameters_vect, vect=countvect)\n",
    "joblib.dump(best_mnb_countvect, './output/best_mnb_countvect.pkl')\n",
    "\n",
    "# LogisticRegression\n",
    "best_logreg_countvect = grid_vect(logreg, parameters_logreg, X_train, X_test, parameters_text=parameters_vect, vect=countvect)\n",
    "joblib.dump(best_logreg_countvect, './output/best_logreg_countvect.pkl')\n",
    "\n",
    "# SVC\n",
    "best_logreg_countvect = grid_vect(svc, parameters_svc, X_train, X_test, parameters_text=parameters_vect, vect=countvect)\n",
    "joblib.dump(best_logreg_countvect, './output/best_svc_countvect.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T16:07:36.724800Z",
     "start_time": "2021-03-01T16:01:18.961439Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['features', 'clf']\n",
      "parameters:\n",
      "{'clf__alpha': (0.25, 0.5, 0.75),\n",
      " 'features__pipe__vect__max_df': (0.25, 0.5, 0.75),\n",
      " 'features__pipe__vect__max_features': (1000, 1500, 2000, 2500),\n",
      " 'features__pipe__vect__min_df': (1, 2),\n",
      " 'features__pipe__vect__ngram_range': ((1, 1), (1, 2))}\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "done in 10.796s\n",
      "\n",
      "Best CV score: 0.950\n",
      "Best parameters set:\n",
      "\tclf__alpha: 0.25\n",
      "\tfeatures__pipe__vect__max_df: 0.5\n",
      "\tfeatures__pipe__vect__max_features: 2500\n",
      "\tfeatures__pipe__vect__min_df: 1\n",
      "\tfeatures__pipe__vect__ngram_range: (1, 1)\n",
      "Test score with best_estimator_: 0.843\n",
      "\n",
      "\n",
      "Classification Report Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.68      0.76       122\n",
      "           1       0.83      0.94      0.88       202\n",
      "\n",
      "    accuracy                           0.84       324\n",
      "   macro avg       0.85      0.81      0.82       324\n",
      "weighted avg       0.85      0.84      0.84       324\n",
      "\n",
      "Performing grid search...\n",
      "pipeline: ['features', 'clf']\n",
      "parameters:\n",
      "{'clf__C': (0.25, 0.5, 1.0),\n",
      " 'clf__penalty': ('l1', 'l2'),\n",
      " 'features__pipe__vect__max_df': (0.25, 0.5, 0.75),\n",
      " 'features__pipe__vect__max_features': (1000, 1500, 2000, 2500),\n",
      " 'features__pipe__vect__min_df': (1, 2),\n",
      " 'features__pipe__vect__ngram_range': ((1, 1), (1, 2))}\n",
      "Fitting 5 folds for each of 288 candidates, totalling 1440 fits\n",
      "done in 23.060s\n",
      "\n",
      "Best CV score: 0.934\n",
      "Best parameters set:\n",
      "\tclf__C: 1.0\n",
      "\tclf__penalty: 'l2'\n",
      "\tfeatures__pipe__vect__max_df: 0.25\n",
      "\tfeatures__pipe__vect__max_features: 2500\n",
      "\tfeatures__pipe__vect__min_df: 2\n",
      "\tfeatures__pipe__vect__ngram_range: (1, 2)\n",
      "Test score with best_estimator_: 0.830\n",
      "\n",
      "\n",
      "Classification Report Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.58      0.72       122\n",
      "           1       0.80      0.98      0.88       202\n",
      "\n",
      "    accuracy                           0.83       324\n",
      "   macro avg       0.87      0.78      0.80       324\n",
      "weighted avg       0.85      0.83      0.82       324\n",
      "\n",
      "Performing grid search...\n",
      "pipeline: ['features', 'clf']\n",
      "parameters:\n",
      "{'clf__C': [1, 10, 100, 1000],\n",
      " 'clf__gamma': [1, 0.1, 0.01, 0.001],\n",
      " 'clf__kernel': ['rbf', 'poly', 'sigmoid'],\n",
      " 'features__pipe__vect__max_df': (0.25, 0.5, 0.75),\n",
      " 'features__pipe__vect__max_features': (1000, 1500, 2000, 2500),\n",
      " 'features__pipe__vect__min_df': (1, 2),\n",
      " 'features__pipe__vect__ngram_range': ((1, 1), (1, 2))}\n",
      "Fitting 5 folds for each of 2304 candidates, totalling 11520 fits\n",
      "done in 342.984s\n",
      "\n",
      "Best CV score: 0.925\n",
      "Best parameters set:\n",
      "\tclf__C: 10\n",
      "\tclf__gamma: 0.01\n",
      "\tclf__kernel: 'rbf'\n",
      "\tfeatures__pipe__vect__max_df: 0.5\n",
      "\tfeatures__pipe__vect__max_features: 2500\n",
      "\tfeatures__pipe__vect__min_df: 1\n",
      "\tfeatures__pipe__vect__ngram_range: (1, 1)\n",
      "Test score with best_estimator_: 0.827\n",
      "\n",
      "\n",
      "Classification Report Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.70      0.75       122\n",
      "           1       0.83      0.90      0.87       202\n",
      "\n",
      "    accuracy                           0.83       324\n",
      "   macro avg       0.82      0.80      0.81       324\n",
      "weighted avg       0.83      0.83      0.82       324\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./output/best_svc_countvect.joblib']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfvect = TfidfVectorizer(stop_words=stopwords.words('french'))\n",
    "\n",
    "# MultinomialNB\n",
    "best_mnb_tfidf = grid_vect(mnb, parameters_mnb, X_train, X_test, parameters_text=parameters_vect, vect=tfidfvect)\n",
    "joblib.dump(best_mnb_tfidf, './output/best_mnb_tfidf.joblib')\n",
    "\n",
    "# LogisticRegression\n",
    "best_logreg_tfidf = grid_vect(logreg, parameters_logreg, X_train, X_test, parameters_text=parameters_vect, vect=tfidfvect)\n",
    "joblib.dump(best_logreg_tfidf, './output/best_logreg_tfidf.joblib')\n",
    "\n",
    "# SVC\n",
    "best_logreg_countvect = grid_vect(svc, parameters_svc, X_train, X_test, parameters_text=parameters_vect, vect=countvect)\n",
    "joblib.dump(best_logreg_countvect, './output/best_svc_countvect.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-01T15:15:22.267320Z",
     "start_time": "2021-03-01T15:15:22.169341Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=5,\n",
      "             estimator=Pipeline(steps=[('features',\n",
      "                                        FeatureUnion(n_jobs=-1,\n",
      "                                                     transformer_list=[('pipe',\n",
      "                                                                        Pipeline(steps=[('vect',\n",
      "                                                                                         TfidfVectorizer(max_df=0.8,\n",
      "                                                                                                         max_features=2500,\n",
      "                                                                                                         min_df=7,\n",
      "                                                                                                         stop_words=['au',\n",
      "                                                                                                                     'aux',\n",
      "                                                                                                                     'avec',\n",
      "                                                                                                                     'ce',\n",
      "                                                                                                                     'ces',\n",
      "                                                                                                                     'dans',\n",
      "                                                                                                                     'de',\n",
      "                                                                                                                     'des',\n",
      "                                                                                                                     'du',\n",
      "                                                                                                                     'elle',\n",
      "                                                                                                                     'en',\n",
      "                                                                                                                     'et',\n",
      "                                                                                                                     'eux',\n",
      "                                                                                                                     'il',\n",
      "                                                                                                                     'ils',\n",
      "                                                                                                                     'je',\n",
      "                                                                                                                     'la',\n",
      "                                                                                                                     'le',\n",
      "                                                                                                                     'les',\n",
      "                                                                                                                     'leur',\n",
      "                                                                                                                     'lui',\n",
      "                                                                                                                     'ma',\n",
      "                                                                                                                     'mais',\n",
      "                                                                                                                     'me',\n",
      "                                                                                                                     'même',\n",
      "                                                                                                                     'mes',\n",
      "                                                                                                                     'moi',\n",
      "                                                                                                                     'mon',\n",
      "                                                                                                                     'ne',\n",
      "                                                                                                                     'nos', ...]))]))])),\n",
      "                                       ('clf', MultinomialNB())]),\n",
      "             n_jobs=-1,\n",
      "             param_grid={'clf__alpha': (0.25, 0.5, 0.75),\n",
      "                         'features__pipe__vect__max_df': (0.25, 0.5, 0.75),\n",
      "                         'features__pipe__vect__min_df': (1, 2),\n",
      "                         'features__pipe__vect__ngram_range': ((1, 1), (1, 2))},\n",
      "             scoring='roc_auc', verbose=1)\n"
     ]
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "import joblib\n",
    "\n",
    "pipeline = joblib.load('./output/best_mnb_tfidf.joblib')\n",
    "print(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 50\n",
    "\n",
    "X_train['clean_text_wordlist'] = X_train.clean_text.apply(lambda x : word_tokenize(x))\n",
    "X_test['clean_text_wordlist'] = X_test.clean_text.apply(lambda x : word_tokenize(x))\n",
    "\n",
    "model = gensim.models.Word2Vec(X_train.clean_text_wordlist\n",
    ", min_count=1\n",
    ", size=SIZE\n",
    ", window=5\n",
    ", workers=4)\n",
    "\n",
    "model.most_similar('plane', topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_avg_w2v_vector(w2v_dict, tweet):\n",
    "    list_of_word_vectors = [w2v_dict[w] for w in tweet if w in w2v_dict.vocab.keys()]\n",
    "    \n",
    "    if len(list_of_word_vectors) == 0:\n",
    "        result = [0.0]*SIZE\n",
    "    else:\n",
    "        result = np.sum(list_of_word_vectors, axis=0) / len(list_of_word_vectors)\n",
    "        \n",
    "    return resultX_train_w2v = X_train['clean_text_wordlist'].apply(lambda x: compute_avg_w2v_vector(model.wv, x))\n",
    "X_test_w2v = X_test['clean_text_wordlist'].apply(lambda x: compute_avg_w2v_vector(model.wv, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_w2v = pd.DataFrame(X_train_w2v.values.tolist(), index= X_train.index)\n",
    "X_test_w2v = pd.DataFrame(X_test_w2v.values.tolist(), index= X_test.index)# Concatenate with the TextCounts variables\n",
    "X_train_w2v = pd.concat([X_train_w2v, X_train.drop(['clean_text', 'clean_text_wordlist'], axis=1)], axis=1)\n",
    "X_test_w2v = pd.concat([X_test_w2v, X_test.drop(['clean_text', 'clean_text_wordlist'], axis=1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_logreg_w2v = grid_vect(logreg, parameters_logreg, X_train_w2v, X_test_w2v, is_w2v=True)\n",
    "joblib.dump(best_logreg_w2v, './output/best_logreg_w2v.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Preprocessing + Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-02T09:27:38.511410Z",
     "start_time": "2021-03-02T09:27:38.403945Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-02T09:54:04.630722Z",
     "start_time": "2021-03-02T09:54:04.621452Z"
    }
   },
   "outputs": [],
   "source": [
    "#Use the key for the classifier followed by __ and the attribute\n",
    "\n",
    "# Parameter grid settings for the vectorizers (Count and TFIDF)\n",
    "parameters_vect = {\n",
    "    'features__pipe__vect__max_df': (0.25, 0.5, 0.75),\n",
    "    'features__pipe__vect__ngram_range': ((1, 1), (1, 2)),\n",
    "    'features__pipe__vect__min_df': (1,2),\n",
    "    'features__pipe__vect__max_features': (1000,1500,2000,2500)\n",
    "}\n",
    "# Parameter grid settings for MultinomialNB\n",
    "parameters_mnb = {\n",
    "    'clf__alpha': (0.25, 0.5, 0.75),\n",
    "    'clf__fit_prior': [True, False] \n",
    "}\n",
    "# Parameter grid settings for LogisticRegression\n",
    "parameters_logreg = {\n",
    "    'clf__C': (0.25, 0.5, 1.0),\n",
    "    'clf__penalty': ('l1', 'l2'),\n",
    "    'clf__solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'clf__max_iter': [20, 50, 100],\n",
    "}\n",
    "\n",
    "# Parameter grid settings for SVC\n",
    "parameters_svc = {\n",
    "    'clf__C': [1, 10, 100,1000], \n",
    "    'clf__gamma': [1,0.1,0.01,0.001],\n",
    "    'clf__kernel': ['rbf', 'poly', 'sigmoid']\n",
    "}\n",
    "\n",
    "# Parameter grid settings for VotingClassifier\n",
    "parameters_vc = {\n",
    "    'lr__C': [0.25, 0.5, 1.0], \n",
    "    'lf__penalty': ['l1', 'l2'],\n",
    "    'lr__solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'lr__max_iter': [20, 50, 100],\n",
    "    'lr__multi_class': ['ovr','multinomial'],\n",
    "    'mnb__alpha': [0.25, 0.5, 0.75],\n",
    "    'mnb__fit_prior': [True, False],\n",
    "    'gboost__n_estimator':[10,20],\n",
    "    'gboost__loss':[\"deviance\",\"exponential\"],\n",
    "    'gboost__learning_rate': [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n",
    "    'gboost__min_samples_split': np.linspace(0.1, 0.5, 12),\n",
    "    'gboost__min_samples_leaf': np.linspace(0.1, 0.5, 12),\n",
    "    'gboost__max_depth':[3,5,8],\n",
    "    'gboost__max_features':[\"log2\",\"sqrt\"],\n",
    "    'gboost__criterion': [\"friedman_mse\", \"mse\",  \"mae\"],\n",
    "    'gboost__subsample':[0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n",
    "    'svm__C': [1, 10, 100,1000], \n",
    "    'svm__gamma': [1,0.1,0.01,0.001],\n",
    "    'svm__kernel': ['rbf', 'poly', 'sigmoid'],\n",
    "    'knn__n-neighbors':[1,2,3,4,5,6,7,8,9,10],\n",
    "    'knn__weights':['distance', 'uniform'],\n",
    "    'knn__p':[1,2],\n",
    "    'rfc__n_estimators': [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)],\n",
    "    'rfc__max_features': ['auto', 'sqrt'],\n",
    "    'rfc__max_depth': [int(x) for x in np.linspace(10, 110, num = 11)],\n",
    "    'rfc__min_samples_split': [2, 5, 10],\n",
    "    'rfc__min_samples_leaf': [1, 2, 4],\n",
    "    'rfc__bootstrap': [True, False],\n",
    "    'var_smoothing': np.logspace(0,-9, num=100)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-02T09:54:05.163929Z",
     "start_time": "2021-03-02T09:54:05.160412Z"
    }
   },
   "outputs": [],
   "source": [
    "clf1 = LogisticRegression()\n",
    "clf2 = RandomForestClassifier()\n",
    "clf3 = GaussianNB()\n",
    "clf4 = MultinomialNB()\n",
    "clf5 = SVC()\n",
    "clf6 = KNeighborsClassifier()\n",
    "clf7 = GradientBoostingClassifier()\n",
    "\n",
    "tfidfvect = TfidfVectorizer(stop_words=stopwords.words('french'))\n",
    "countvect = CountVectorizer(stop_words=stopwords.words('french')) #token_pattern=r'\\b\\w+\\b',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-02T10:05:52.021774Z",
     "start_time": "2021-03-02T10:05:52.009448Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ComplementNB' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-48e5d02928e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m bow_pipeline = Pipeline(\n\u001b[1;32m      2\u001b[0m     steps=[(\"BOW\", CountVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words=stopwords.words('french'))),\n\u001b[0;32m----> 3\u001b[0;31m         ('Voting', VotingClassifier(estimators=[('Naive bayes complement', ComplementNB()),(\"Naive bayes multinomial\", MultinomialNB()),(\"LR\", LogisticRegression()), (\"KNN\",neighbors.KNeighborsClassifier(n_neighbors = 5,p=1,weights=\"distance\")) ], voting='hard'))])\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mbow_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_pip_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbow_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ComplementNB' is not defined"
     ]
    }
   ],
   "source": [
    "bow_pipeline = Pipeline(\n",
    "    steps=[(\"BOW\", CountVectorizer(max_df=0.90, min_df=2, max_features=1000, stop_words=stopwords.words('french'))),\n",
    "        ('Voting', VotingClassifier(estimators=[('Naive bayes complement', ComplementNB()),(\"Naive bayes multinomial\", MultinomialNB()),(\"LR\", LogisticRegression()), (\"KNN\",neighbors.KNeighborsClassifier(n_neighbors = 5,p=1,weights=\"distance\")) ], voting='hard'))])\n",
    "\n",
    "bow_pipeline.fit(X_pip_train, y_train)\n",
    "y_pred = bow_pipeline.predict(X_test)\n",
    "\n",
    "\n",
    "f1_s = f1_score(y_test, y_pred)\n",
    "roc_s = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print (grid.best_params_)\n",
    "print('F1-score: ', f1_s)\n",
    "print('Roc curve:', roc_pip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-02T10:04:39.430696Z",
     "start_time": "2021-03-02T10:04:39.412025Z"
    }
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-115-b2cdb6931d24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meclf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters_vc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1286\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1288\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    785\u001b[0m                                     more_results=None):\n\u001b[1;32m    786\u001b[0m                 \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcv_orig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                 \u001b[0mcandidate_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m                 \u001b[0mn_candidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "eclf1 = VotingClassifier(estimators=[\n",
    "    ('lr', clf1), \n",
    "    ('rf', clf2), \n",
    "    ('gnb', clf3),\n",
    "    ('mnb', clf4),\n",
    "    ('svc', clf5),\n",
    "    ('knn', clf6),\n",
    "    ('gbc', clf7)\n",
    "    ], voting='hard')\n",
    "\n",
    "#eclf2 = VotingClassifier(estimators=[ \n",
    "#    ('lr', clf1), \n",
    "#    ('rf', clf2), \n",
    "#    ('gnb', clf3),\n",
    "#    ('mnb', clf4),\n",
    "#    ('svc', clf5),\n",
    "#    ('knn', clf6),\n",
    "#    ('gbc', clf7),\n",
    "#    ], voting='soft')\n",
    "\n",
    "\n",
    "grid = GridSearchCV(estimator=eclf1, param_grid=parameters_vc, scoring = 'roc_auc', cv=5)\n",
    "\n",
    "grid.fit(X_train,y_train)\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "f1_s = f1_score(y_test, y_pred)\n",
    "roc_s = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print (grid.best_params_)\n",
    "print('F1-score: ', f1_s)\n",
    "print('Roc curve:', roc_pip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-02T09:58:27.691617Z",
     "start_time": "2021-03-02T09:58:27.689737Z"
    }
   },
   "outputs": [],
   "source": [
    "#best_vc_tfidf = grid_vect(eclf1, parameters_vc, X_train, X_test, parameters_text=parameters_vect, vect=tfidfvect)\n",
    "#joblib.dump(best_vc_tfidf, './output/best_vc_tfidf.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-02T09:58:32.764169Z",
     "start_time": "2021-03-02T09:58:32.762402Z"
    }
   },
   "outputs": [],
   "source": [
    "#best_vc_tfidf = grid_vect(eclf1, parameters_vc, X_train, X_test, parameters_text=parameters_vect, vect=countvect)\n",
    "#joblib.dump(best_vc_countvect, './output/best_vc_countvect.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
